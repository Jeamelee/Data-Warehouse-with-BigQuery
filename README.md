# Data-Warehouse-with-BigQuery

Designing and Implementing a Data Warehouse for Nestle Marketing and Distribution
üéØ Project Overview
This project involved the design, implementation, and analysis of a data warehouse solution specifically tailored for the Marketing and Distribution Department of Nestle. The primary goal was to transform raw sales and purchase data into a structured, query-optimized format to support advanced business intelligence (BI) reporting and analytical decision-making.

The project successfully demonstrated proficiency in data warehousing principles, the ETL (Extract, Transform, Load) process, dimensional modeling (Star Schema), and data retrieval using advanced SQL techniques.

Final Project Outcome: 96%

üí° Technologies and Architecture
This project utilized a modern cloud-based approach to data warehousing, focusing on scalability and performance.

Technology

Role

Google BigQuery

Primary cloud data warehouse platform for storage and querying.

SQL

Used for dimensional modeling, ETL scripting, and generating all business intelligence reports.

Dimensional Modeling

Implemented a Star Schema consisting of the Sales Fact Table and multiple Dimension Tables.

ETL Process

Focused on extracting data from source tables, transforming it into a dimensional structure, and loading it into the BigQuery warehouse.

üìê Data Warehouse Schema
The data warehouse was structured using a Star Schema, focusing on sales performance. The key components include:

Fact Table
Sales (Fact): Contains measurable metrics related to transactions. (Note: This was the sole fact table used for the ETL process.)

Dimension Tables
The following dimension tables were created to enable slicing and dicing of the sales data:

Country

Customer

Date

Payment

Product

Salesperson

Store

üíª Business Intelligence Queries
The final deliverable included several critical SQL queries designed to extract key business insights for the Marketing and Distribution Department. These queries allow users to derive valuable intelligence by analyzing sales data across various dimensions:

Insight Generated

Description

Total Sale by Product

Provides a clear breakdown of revenue generated by each product line.

Sale Trend Over Time

Tracks sales performance monthly or annually to identify seasonality and growth.

Top Performing Salesperson

Identifies the most successful salespeople based on total sales value.

Customer Purchase Frequency

Analyzes how often different customer segments make purchases.

Sale by Region

Compares sales performance across different geographic regions (e.g., Europe).

Payment Method Analysis

Enables reporting on sales categorized by payment type (Cash, Credit Card, etc.).

‚≠ê My Role and Contribution
I took on the roles of sole Data Analyst and Project Manager for this project, which was technically a two-person group assignment. My responsibilities encompassed the entire lifecycle:

Design: Conceptualizing the dimensional model and determining the required fact and dimension tables.

Implementation (ETL): Writing and executing the SQL scripts to transform and load the raw data into the BigQuery data warehouse structure.

Analysis: Developing and executing advanced SQL queries to generate actionable business intelligence reports.

Collaboration and Guidance:

Coursera Course: I independently utilized the "Build a Data Warehouse Using BigQuery" course to guide the implementation of best practices for cloud data warehousing.

Lecturer Guidance: I worked closely with my lecturer to receive feedback and ensure the design and implementation met all academic and technical requirements.

üöÄ Getting Started (Simulated)
This section outlines the general steps required to replicate a similar setup in Google BigQuery.

Set up Google Cloud: Ensure you have a Google Cloud project with the BigQuery API enabled.

Create Dataset: Create a BigQuery Dataset (e.g., Nestle_DataWarehouse).

Load Source Data: Load your raw sales and purchase data into initial staging tables (e.g., Nestle_Sales_and_Purchase).

Execute ETL: Run the dimensional modeling SQL scripts (similar to those provided in the project) to create the Fact and Dimension tables in the Nestle_DataWarehouse Dataset.

Run Queries: Execute the BI queries to generate reports and gain insights.
